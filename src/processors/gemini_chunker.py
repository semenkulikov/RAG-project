"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ Gemini —Å —Ä–µ–∑–µ—Ä–≤–æ–º –Ω–∞ ChatGPT
"""

import os
import json
from typing import List, Dict, Any
import google.generativeai as genai
from loguru import logger
from ..utils.config import GEMINI_API_KEY, OPENAI_API_KEY

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    logger.warning("GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. Gemini —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI –¥–ª—è —Ä–µ–∑–µ—Ä–≤–∞
if OPENAI_API_KEY:
    import openai

    openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
else:
    openai_client = None
    logger.warning("OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. ChatGPT —Ä–µ–∑–µ—Ä–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")


class GeminiChunker:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ Gemini —Å —Ä–µ–∑–µ—Ä–≤–æ–º –Ω–∞ ChatGPT"""

    def __init__(self):
        self.setup_logging()
        self.cache_file = "./data/gemini_chunking_cache.json"
        self.cache = self.load_cache()

    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.add("./logs/gemini_chunker.log", rotation="1 MB", level="INFO")

    def load_cache(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, "r", encoding="utf-8") as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫—ç—à: {e}")
        return {}

    def save_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è"""
        try:
            os.makedirs(os.path.dirname(self.cache_file), exist_ok=True)
            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à: {e}")

    def get_cache_key(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        import hashlib

        return hashlib.md5(text.encode("utf-8")).hexdigest()

    def extract_json_from_response(self, response_text: str) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
            json_patterns = [
                r"```json\s*(.*?)\s*```",
                r"```\s*(.*?)\s*```",
                r"\{.*\}",
            ]

            import re

            for pattern in json_patterns:
                matches = re.findall(pattern, response_text, re.DOTALL)
                if matches:
                    json_text = matches[0].strip()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π JSON
                    json.loads(json_text)
                    return json_text

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –±–ª–æ–∫–∞—Ö –∫–æ–¥–∞, –∏—â–µ–º JSON –≤ —Ç–µ–∫—Å—Ç–µ
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1

            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                json.loads(json_text)
                return json_text

            return ""

        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            logger.error(f"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç: {response_text[:500]}...")
            if len(response_text) > 500:
                logger.error(f"–û–∫–æ–Ω—á–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞: ...{response_text[-500:]}")
            return ""

    def chunk_with_gemini(self, text: str, source_file: str) -> List[Dict[str, Any]]:
        """–ß–∞–Ω–∫–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Gemini"""
        try:
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
            max_chars = 30000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è Gemini
            if len(text) > max_chars:
                return self.chunk_large_document_gemini(text, source_file)

            prompt = f"""
            –†–∞–∑–±–µ–π —Å–ª–µ–¥—É—é—â–∏–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏. 
            –ö–∞–∂–¥—ã–π —á–∞–Ω–∫ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–Ω—É –ø—Ä–∞–≤–æ–≤—É—é –ø–æ–∑–∏—Ü–∏—é –∏–ª–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –ø–æ –æ–¥–Ω–æ–π –Ω–æ—Ä–º–µ –ø—Ä–∞–≤–∞.
            
            –î–æ–∫—É–º–µ–Ω—Ç: {source_file}
            
            –¢–µ–∫—Å—Ç:
            {text}
            
            –í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
            {{
                "chunks": [
                    {{
                        "title": "–ù–∞–∑–≤–∞–Ω–∏–µ —á–∞–Ω–∫–∞",
                        "text": "–¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞",
                        "type": "factual_circumstances|legal_position|citation|conclusion",
                        "key_articles": ["—Å—Ç. 18 –ó–æ–ó–ü–ü", "—Å—Ç. 15 –ì–ö –†–§"],
                        "legal_concepts": ["–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ —Ç–æ–≤–∞—Ä–∞", "–ø—Ä–∞–≤–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è"]
                    }}
                ]
            }}
            """

            model = genai.GenerativeModel("gemini-2.0-flash-exp")
            response = model.generate_content(prompt)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            response_text = response.text
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                json_text = response_text[json_start:json_end].strip()
            else:
                json_text = response_text

            result = json.loads(json_text)
            chunks = result.get("chunks", [])

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            processed_chunks = []
            for i, chunk in enumerate(chunks):
                processed_chunks.append(
                    {
                        "id": f"{source_file}_gemini_chunk_{i}",
                        "text": chunk.get("text", ""),
                        "type": chunk.get("type", "legal_text"),
                        "title": chunk.get("title", f"–ß–∞–Ω–∫ {i + 1}"),
                        "key_articles": chunk.get("key_articles", []),
                        "legal_concepts": chunk.get("legal_concepts", []),
                        "source_file": source_file,
                        "chunking_method": "gemini",
                    }
                )

            return processed_chunks

        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Gemini: {e}")
            return self.chunk_with_chatgpt(text, source_file)
        except Exception as e:
            error_msg = str(e)
            if "User location is not supported" in error_msg:
                logger.warning(
                    "‚ö†Ô∏è Gemini API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ. –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ ChatGPT."
                )
                return self.chunk_with_chatgpt(text, source_file)
            else:
                logger.error(f"–û—à–∏–±–∫–∞ Gemini —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è: {e}")
                return self.chunk_with_chatgpt(text, source_file)

    def chunk_large_document_gemini(
        self, text: str, source_file: str
    ) -> List[Dict[str, Any]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–æ–ª—å—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ Gemini –ø–æ —á–∞—Å—Ç—è–º"""
        logger.info(
            f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç {source_file} –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç Gemini. –†–∞–∑–±–∏–≤–∞—é –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
        )

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 20k —Å–∏–º–≤–æ–ª–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º
        chunk_size = 20000
        overlap = 1000
        all_chunks = []

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π
        total_parts = (len(text) + chunk_size - overlap - 1) // (chunk_size - overlap)
        logger.info(
            f"üìä –î–æ–∫—É–º–µ–Ω—Ç –±—É–¥–µ—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {total_parts} —á–∞—Å—Ç–µ–π –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
        )

        start = 0
        part_num = 0

        while start < len(text):
            end = min(start + chunk_size, len(text))
            part_text = text[start:end]

            logger.info(
                f"üìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —á–∞—Å—Ç—å {part_num + 1}/{total_parts} –¥–æ–∫—É–º–µ–Ω—Ç–∞ {source_file}"
            )

            try:
                part_chunks = self.chunk_with_gemini(
                    part_text, f"{source_file}_part_{part_num}"
                )

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                for chunk in part_chunks:
                    chunk["id"] = f"{source_file}_gemini_part_{part_num}_{chunk['id']}"
                    chunk["title"] = (
                        f"{chunk['title']} (—á–∞—Å—Ç—å {part_num + 1}/{total_parts})"
                    )
                    chunk["part_info"] = f"—á–∞—Å—Ç—å {part_num + 1}/{total_parts}"

                all_chunks.extend(part_chunks)

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Å—Ç–∏ {part_num + 1}: {e}")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º ChatGPT –¥–ª—è —ç—Ç–æ–π —á–∞—Å—Ç–∏
                try:
                    chatgpt_chunks = self.chunk_with_chatgpt(
                        part_text, f"{source_file}_part_{part_num}"
                    )
                    all_chunks.extend(chatgpt_chunks)
                except Exception as e2:
                    logger.error(f"–û—à–∏–±–∫–∞ ChatGPT –¥–ª—è —á–∞—Å—Ç–∏ {part_num + 1}: {e2}")
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –¥–ª—è —ç—Ç–æ–π —á–∞—Å—Ç–∏
                    fallback_chunks = self.fallback_chunking(
                        part_text, f"{source_file}_part_{part_num}"
                    )
                    all_chunks.extend(fallback_chunks)

            part_num += 1
            start = end - overlap  # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

        logger.info(
            f"‚úÖ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(all_chunks)} —á–∞–Ω–∫–æ–≤"
        )
        return all_chunks

    def chunk_with_chatgpt(self, text: str, source_file: str) -> List[Dict[str, Any]]:
        """–†–µ–∑–µ—Ä–≤–Ω–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ ChatGPT"""
        if not openai_client:
            logger.error("OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            return self.fallback_chunking(text, source_file)

        try:
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
            max_chars = 5000  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è ChatGPT
            if len(text) > max_chars:
                return self.chunk_large_document_chatgpt(text, source_file)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            return self.chunk_with_chatgpt_simple(text, source_file)

        except Exception as e:
            error_msg = str(e)
            if (
                "unsupported_country_region_territory" in error_msg
                or "Country, region, or territory not supported" in error_msg
            ):
                logger.warning(
                    "‚ö†Ô∏è OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ."
                )
            else:
                logger.error(f"–û—à–∏–±–∫–∞ ChatGPT —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è: {e}")
            return self.fallback_chunking(text, source_file)

    def chunk_large_document_chatgpt(
        self, text: str, source_file: str
    ) -> List[Dict[str, Any]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–æ–ª—å—à–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ ChatGPT –ø–æ —á–∞—Å—Ç—è–º"""
        logger.info(
            f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç {source_file} –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç ChatGPT. –†–∞–∑–±–∏–≤–∞—é –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
        )

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 3k —Å–∏–º–≤–æ–ª–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä)
        chunk_size = 3000
        overlap = 200
        all_chunks = []

        start = 0
        part_num = 0

        while start < len(text):
            end = min(start + chunk_size, len(text))
            part_text = text[start:end]
            part_num += 1

            logger.info(
                f"üìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —á–∞—Å—Ç—å {part_num} –¥–æ–∫—É–º–µ–Ω—Ç–∞ {source_file} ({len(part_text)} —Å–∏–º–≤–æ–ª–æ–≤)"
            )

            try:
                # –ü—Ä–æ—Å—Ç–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
                part_chunks = self.chunk_with_chatgpt_simple(
                    part_text, f"{source_file}_part_{part_num}"
                )

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                for chunk in part_chunks:
                    chunk["id"] = f"{source_file}_chatgpt_part_{part_num}_{chunk['id']}"
                    chunk["title"] = f"{chunk['title']} (—á–∞—Å—Ç—å {part_num})"

                all_chunks.extend(part_chunks)
                logger.info(f"‚úÖ –ß–∞—Å—Ç—å {part_num} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞: {len(part_chunks)} —á–∞–Ω–∫–æ–≤")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞—Å—Ç–∏ {part_num}: {e}")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –¥–ª—è —ç—Ç–æ–π —á–∞—Å—Ç–∏
                fallback_chunks = self.fallback_chunking(
                    part_text, f"{source_file}_part_{part_num}"
                )
                all_chunks.extend(fallback_chunks)

            start = end - overlap  # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

        logger.info(
            f"‚úÖ –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(all_chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ {part_num} —á–∞—Å—Ç–µ–π"
        )
        return all_chunks

    def chunk_with_chatgpt_simple(self, text: str, source_file: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ—Å—Ç–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ ChatGPT –±–µ–∑ —Å–ª–æ–∂–Ω–æ–π –ª–æ–≥–∏–∫–∏"""
        if not openai_client:
            logger.error("OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            return self.fallback_chunking(text, source_file)

        try:
            prompt = f"""
            –†–∞–∑–±–µ–π —Å–ª–µ–¥—É—é—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —á–∞–Ω–∫–∏. 
            –ö–∞–∂–¥—ã–π —á–∞–Ω–∫ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–Ω—É –ø—Ä–∞–≤–æ–≤—É—é –ø–æ–∑–∏—Ü–∏—é –∏–ª–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –ø–æ –æ–¥–Ω–æ–π –Ω–æ—Ä–º–µ –ø—Ä–∞–≤–∞.
            
            –í–ê–ñ–ù–û: –í–µ—Ä–Ω–∏ –ü–û–õ–ù–´–ô JSON –æ—Ç–≤–µ—Ç –±–µ–∑ –æ–±—Ä–µ–∑–∞–Ω–∏—è. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω—ã–π, —Å–æ–∑–¥–∞–π –±–æ–ª—å—à–µ —á–∞–Ω–∫–æ–≤, –Ω–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∏ JSON –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
            
            –î–æ–∫—É–º–µ–Ω—Ç: {source_file}
            
            –¢–µ–∫—Å—Ç:
            {text}
            
            –í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ü–û–õ–ù–´–ô):
            {{
                "chunks": [
                    {{
                        "title": "–ù–∞–∑–≤–∞–Ω–∏–µ —á–∞–Ω–∫–∞",
                        "text": "–¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞",
                        "type": "factual_circumstances|legal_position|citation|conclusion",
                        "key_articles": ["—Å—Ç. 18 –ó–æ–ó–ü–ü", "—Å—Ç. 15 –ì–ö –†–§"],
                        "legal_concepts": ["–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ —Ç–æ–≤–∞—Ä–∞", "–ø—Ä–∞–≤–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è"]
                    }}
                ]
            }}
            """

            response = openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Ä–∞–∑–±–∏—Ç—å —Å—É–¥–µ–±–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.1,
                max_tokens=3000,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                timeout=60,
            )

            response_text = response.choices[0].message.content

            # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            json_text = self.extract_json_from_response(response_text)

            if not json_text:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ ChatGPT")
                logger.error(f"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç ChatGPT: {response_text}")
                return self.fallback_chunking(text, source_file)

            result = json.loads(json_text)
            chunks = result.get("chunks", [])

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            processed_chunks = []
            for i, chunk in enumerate(chunks):
                processed_chunks.append(
                    {
                        "id": f"{source_file}_chatgpt_chunk_{i}",
                        "text": chunk.get("text", ""),
                        "type": chunk.get("type", "legal_text"),
                        "title": chunk.get("title", f"–ß–∞–Ω–∫ {i + 1}"),
                        "key_articles": chunk.get("key_articles", []),
                        "legal_concepts": chunk.get("legal_concepts", []),
                        "source_file": source_file,
                        "chunking_method": "chatgpt",
                    }
                )

            return processed_chunks

        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç ChatGPT: {e}")
            return self.fallback_chunking(text, source_file)
        except Exception as e:
            error_msg = str(e)
            if (
                "unsupported_country_region_territory" in error_msg
                or "Country, region, or territory not supported" in error_msg
            ):
                logger.warning(
                    "‚ö†Ô∏è OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ."
                )
            else:
                logger.error(f"–û—à–∏–±–∫–∞ ChatGPT —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è: {e}")
            return self.fallback_chunking(text, source_file)


    def fallback_chunking(self, text: str, source_file: str) -> List[Dict[str, Any]]:
        """–†–µ–∑–µ—Ä–≤–Ω–æ–µ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ –ø–æ –∞–±–∑–∞—Ü–∞–º"""
        chunks = []
        paragraphs = text.split("\n\n")
        chunk_id = 0

        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if len(paragraph) > 100:  # –¢–æ–ª—å–∫–æ –∑–Ω–∞—á–∏–º—ã–µ –∞–±–∑–∞—Ü—ã
                chunks.append(
                    {
                        "id": f"{source_file}_fallback_chunk_{chunk_id}",
                        "text": paragraph,
                        "type": "legal_text",
                        "title": f"–ê–±–∑–∞—Ü {chunk_id + 1}",
                        "key_articles": [],
                        "legal_concepts": [],
                        "source_file": source_file,
                        "chunking_method": "fallback",
                    }
                )
                chunk_id += 1

        return chunks

    def chunk_document(self, text: str, source_file: str) -> List[Dict[str, Any]]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏ —á–µ—Ä–µ–∑ Gemini —Å —Ä–µ–∑–µ—Ä–≤–æ–º –Ω–∞ ChatGPT

        Args:
            text: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
            source_file: –ò–º—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = self.get_cache_key(text)
        if cache_key in self.cache:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {source_file}")
            return self.cache[cache_key]

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        text_length = len(text)
        if text_length > 50000:
            logger.info(f"üöÄ –ë–æ–ª—å—à–æ–π –¥–æ–∫—É–º–µ–Ω—Ç {source_file}: {text_length:,} —Å–∏–º–≤–æ–ª–æ–≤")
            logger.info("‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ–º ChatGPT –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            try:
                chunks = self.chunk_with_chatgpt(text, source_file)
                self.cache[cache_key] = chunks
                self.save_cache()
                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è {source_file}")
                return chunks
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ ChatGPT –¥–ª—è –±–æ–ª—å—à–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")

        try:
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º Gemini —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ –¥–ª—è {source_file}")
            chunks = self.chunk_with_gemini(text, source_file)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self.cache[cache_key] = chunks
            self.save_cache()

            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è {source_file}")
            return chunks

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á–∞–Ω–∫–æ–≤–∞–Ω–∏–∏: {e}")
            return self.fallback_chunking(text, source_file)

    def estimate_cost(self, text: str) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞)
        input_tokens = len(text) / 4
        output_tokens = input_tokens * 0.3  # –ü—Ä–∏–º–µ—Ä–Ω–æ 30% –æ—Ç –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤

        # –°—Ç–æ–∏–º–æ—Å—Ç—å Gemini (–ø—Ä–∏–º–µ—Ä–Ω–∞—è)
        gemini_cost = (input_tokens * 0.000075 + output_tokens * 0.0003) / 1000

        # –°—Ç–æ–∏–º–æ—Å—Ç—å ChatGPT (–ø—Ä–∏–º–µ—Ä–Ω–∞—è)
        chatgpt_cost = (input_tokens * 0.03 + output_tokens * 0.06) / 1000

        return {
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "estimated_cost_gemini_usd": gemini_cost,
            "estimated_cost_chatgpt_usd": chatgpt_cost,
            "estimated_cost_usd": min(
                gemini_cost, chatgpt_cost
            ),  # –ë–µ—Ä–µ–º –º–µ–Ω—å—à—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å
        }
